# Agricultural Disease Recognition

**"Talk is cheap. Show me the code."** - Linus Torvalds

æ·±åº¦å­¦ä¹ å†œä½œç‰©ç—…å®³è¯†åˆ«ç³»ç»Ÿ - 61ç±»ç–¾ç—…åˆ†ç±»ä¸å¤šä»»åŠ¡å­¦ä¹ 

## ğŸ“ Project Structure

```
ShuWeiCamp/
â”œâ”€â”€ src/                    # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ __init__.py        # åŒ…åˆå§‹åŒ–
â”‚   â”œâ”€â”€ data_structures.py # æ ‡ç­¾å±‚æ¬¡ç»“æ„
â”‚   â”œâ”€â”€ dataset.py         # æ•°æ®é›†å®ç°
â”‚   â”œâ”€â”€ models.py          # æ¨¡å‹æ¶æ„
â”‚   â”œâ”€â”€ losses.py          # æŸå¤±å‡½æ•°
â”‚   â””â”€â”€ trainer.py         # è®­ç»ƒå™¨
â”œâ”€â”€ scripts/               # å·¥å…·è„šæœ¬
â”‚   â”œâ”€â”€ data_cleaner.py    # æ•°æ®æ¸…ç†
â”‚   â”œâ”€â”€ evaluate.py        # æ¨¡å‹è¯„ä¼°
â”‚   â”œâ”€â”€ task4_evaluate.py  # Task4 è¯„ä¼°
â”‚   â””â”€â”€ task4_inference_demo.py  # æ¨ç†æ¼”ç¤º
â”œâ”€â”€ docs/                  # æ–‡æ¡£å’Œè®­ç»ƒè®°å½•
â”œâ”€â”€ task1train.py          # Task 1: 61ç±»åˆ†ç±»è®­ç»ƒ
â”œâ”€â”€ task2train.py          # Task 2: ä½œç‰©ç±»å‹åˆ†ç±»
â”œâ”€â”€ task3train.py          # Task 3: ç—…å®³ä¸¥é‡ç¨‹åº¦åˆ†ç±»
â”œâ”€â”€ task4train.py          # Task 4: å¤šä»»åŠ¡è”åˆè®­ç»ƒ
â”œâ”€â”€ config_task1.yaml      # è®­ç»ƒé…ç½®
â””â”€â”€ README.md              # æœ¬æ–‡ä»¶
```

## ğŸš€ Quick Start

### 1. æ•°æ®å‡†å¤‡

```bash
# æ¸…ç†å’Œé¢„å¤„ç†æ•°æ®
python scripts/data_cleaner.py --src data/raw --dst data/cleaned
```

### 2. è®­ç»ƒæ¨¡å‹

```bash
# Task 1: 61ç±»ç—…å®³åˆ†ç±»
python task1train.py --config config_task1.yaml

# Task 4: å¤šä»»åŠ¡å­¦ä¹  (æ¨è)
python task4train.py --epochs 50 --batch-size 64 --backbone efficientnet_b3
```

### 3. è¯„ä¼°æ¨¡å‹

```bash
# é€šç”¨è¯„ä¼°
python scripts/evaluate.py --model best.pth --data data/cleaned/val

# Task 4 è¯¦ç»†è¯„ä¼°
python scripts/task4_evaluate.py \
    --checkpoint checkpoints/task4_multitask/best.pth \
    --val-meta data/cleaned/metadata/val_metadata.csv \
    --val-dir data/cleaned/val \
    --out-dir checkpoints/task4_multitask/evaluation
```

### 4. æ¨ç†æ¼”ç¤º

```bash
python scripts/task4_inference_demo.py \
    --checkpoint checkpoints/task4_multitask/best.pth \
    --val-meta data/cleaned/metadata/val_metadata.csv \
    --val-dir data/cleaned/val \
    --out-dir outputs/inference_demo \
    --num-samples 10
```

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ä»»åŠ¡ | æ¨¡å‹ | å‡†ç¡®ç‡ | è¯´æ˜ |
|------|------|--------|------|
| Task 1 | ResNet50 | 70-85% | 61ç±»ç—…å®³åˆ†ç±» |
| Task 2 | EfficientNet-B3 | 90%+ | 10ç±»ä½œç‰©åˆ†ç±» |
| Task 3 | ResNet50 | 85%+ | ç—…å®³ä¸¥é‡ç¨‹åº¦ (3ç±») |
| Task 4 | EfficientNet-B3 (å¤šä»»åŠ¡) | ç»¼åˆæœ€ä¼˜ | è”åˆè®­ç»ƒæ‰€æœ‰ä»»åŠ¡ |

### å…³é”®ç‰¹æ€§

1. **Learning Rate**: 1e-4 â†’ 5e-4 (5x â†‘)
2. **Batch Size**: 64 â†’ 32 (æ›´å¥½çš„æ¢¯åº¦ä¿¡å·)
3. **Warmup**: æ·»åŠ 5 epoch warmup
4. **LR Schedule**: Warmupåæ‰å¼€å§‹decay
5. **å¯è§†åŒ–**: æ¯è½®è‡ªåŠ¨æ›´æ–°è®­ç»ƒæ›²çº¿

## ğŸ“ é¡¹ç›®ç»“æ„

```
ShuWeiCamp/
â”œâ”€â”€ train.py                    # ä¸»è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_improved.sh          # ä¼˜åŒ–ç‰ˆè®­ç»ƒè„šæœ¬ (æ¨èä½¿ç”¨)
â”œâ”€â”€ trainer.py                 # è®­ç»ƒå¼•æ“ (å«å¯è§†åŒ–)
â”œâ”€â”€ models.py                  # æ¨¡å‹å®šä¹‰
â”œâ”€â”€ dataset.py                 # æ•°æ®é›†åŠ è½½
â”œâ”€â”€ losses.py                  # æŸå¤±å‡½æ•°
â”œâ”€â”€ visualize_training.py      # å¯è§†åŒ–å·¥å…·
â”œâ”€â”€ demo_visualization.py      # Demoæ¼”ç¤º
â”‚
â”œâ”€â”€ TRAINING_FIX_SUMMARY.md    # ğŸ”¥ è®­ç»ƒä¿®å¤æ€»ç»“ (å¿…è¯»!)
â”œâ”€â”€ IMPROVEMENTS.md            # è¯¦ç»†æ”¹è¿›æ–‡æ¡£
â”œâ”€â”€ ROADMAP.md                 # é¡¹ç›®è·¯çº¿å›¾
â”œâ”€â”€ SETUP.md                   # ç¯å¢ƒè®¾ç½®
â”‚
â”œâ”€â”€ data/                      # æ•°æ®ç›®å½•
â”‚   â”œâ”€â”€ cleaned/               # æ¸…æ´—åçš„æ•°æ®
â”‚   â””â”€â”€ raw/                   # åŸå§‹æ•°æ®
â”‚
â””â”€â”€ checkpoints/               # æ¨¡å‹æ£€æŸ¥ç‚¹
    â”œâ”€â”€ task1_baseline/        # åŸºçº¿æ¨¡å‹ (27.6%)
    â””â”€â”€ task1_improved/        # ä¼˜åŒ–æ¨¡å‹ (70-85%)
```

## ğŸ“– æ–‡æ¡£å¯¼èˆª

- **[TRAINING_FIX_SUMMARY.md](TRAINING_FIX_SUMMARY.md)** - ğŸ”¥ è®­ç»ƒé—®é¢˜ä¿®å¤æ€»ç»“ (å…ˆçœ‹è¿™ä¸ª!)
- **[IMPROVEMENTS.md](IMPROVEMENTS.md)** - è¯¦ç»†æ”¹è¿›è¯´æ˜å’ŒåŸç†
- **[ROADMAP.md](ROADMAP.md)** - å®Œæ•´é¡¹ç›®è·¯çº¿å›¾
- **[SETUP.md](SETUP.md)** - ç¯å¢ƒé…ç½®æŒ‡å—

## ğŸ› ï¸ å¸¸ç”¨å‘½ä»¤

### è®­ç»ƒç›¸å…³

```bash
# ä½¿ç”¨ä¼˜åŒ–é…ç½®è®­ç»ƒ
bash train_improved.sh

# è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
python train.py --lr 5e-4 --batch-size 32 --epochs 50

# ä»æ–­ç‚¹æ¢å¤è®­ç»ƒ
python train.py --resume checkpoints/task1_improved/interrupted.pth
```

### å¯è§†åŒ–ç›¸å…³

```bash
# æŸ¥çœ‹è®­ç»ƒè¿›åº¦
python visualize_training.py --checkpoint checkpoints/task1_improved/best.pth

# å¯¹æ¯”å¤šä¸ªæ¨¡å‹
python visualize_training.py --compare \
    checkpoints/task1_baseline/best.pth \
    checkpoints/task1_improved/best.pth

# ç”Ÿæˆdemoå›¾è¡¨
python demo_visualization.py
```

### æ•°æ®ç›¸å…³

```bash
# æŸ¥çœ‹æ•°æ®é›†ç»Ÿè®¡
python dataset.py

# æµ‹è¯•æ•°æ®åŠ è½½
python -c "from dataset import *; test_dataset()"
```

## ğŸ¯ è®­ç»ƒæµç¨‹

1. **æ•°æ®å‡†å¤‡** (å·²å®Œæˆ)
   - 61ç±»ç–¾ç—…æ•°æ®
   - Train/Val split
   - Class weightsè®¡ç®—

2. **æ¨¡å‹è®­ç»ƒ** (å½“å‰)
   ```bash
   bash train_improved.sh
   ```

3. **ç›‘æ§è®­ç»ƒ**
   - æŸ¥çœ‹æ§åˆ¶å°è¾“å‡º
   - æ£€æŸ¥ `training_curves.png`
   - åˆ†æoverfittingçŠ¶æ€

4. **æ¨¡å‹è¯„ä¼°**
   - Best checkpointåœ¨ `checkpoints/task1_improved/best.pth`
   - ä½¿ç”¨ `visualize_training.py` æŸ¥çœ‹è¯¦ç»†æŒ‡æ ‡

## ğŸ› æ•…éšœæ’æŸ¥

### å‡†ç¡®ç‡ä½ (<50%)

1. æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ä¼˜åŒ–é…ç½®:
   ```bash
   grep "lr" checkpoints/task1_improved/logs/*
   ```

2. æŸ¥çœ‹è®­ç»ƒæ›²çº¿æ˜¯å¦æ­£å¸¸:
   ```bash
   python visualize_training.py --checkpoint-dir checkpoints/task1_improved/
   ```

3. éªŒè¯æ•°æ®åŠ è½½:
   ```bash
   python -c "from dataset import *; ds = AgriDiseaseDataset('data/cleaned/train', 'data/cleaned/metadata/train_metadata.csv'); print(f'Samples: {len(ds)}')"
   ```

### æ˜¾å­˜ä¸è¶³

```bash
# å‡å°batch size
python train.py --batch-size 16

# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
python train.py --backbone resnet34
```

### è®­ç»ƒå¤ªæ…¢

```bash
# å¢åŠ workers
python train.py --num-workers 8

# å¯ç”¨ç¼–è¯‘ (PyTorch 2.0+)
python train.py --compile
```

## ğŸ“Š ç»“æœå¯è§†åŒ–ç¤ºä¾‹

è®­ç»ƒåè‡ªåŠ¨ç”Ÿæˆçš„å›¾è¡¨åŒ…å«:

1. **Loss Curves** - è®­ç»ƒ/éªŒè¯æŸå¤±
2. **Accuracy Curves** - å‡†ç¡®ç‡å˜åŒ– + æœ€ä½³ç‚¹æ ‡æ³¨
3. **LR Schedule** - å­¦ä¹ ç‡å˜åŒ– (æ˜¾ç¤ºwarmupé˜¶æ®µ)
4. **Overfitting Analysis** - Train-Val gapåˆ†æ

çŠ¶æ€åˆ¤æ–­:
- ğŸŸ¢ Green: Good fit (gap < 5%)
- ğŸŸ¡ Orange: Slight overfitting (5-10%)
- ğŸ”´ Red: Overfitting (> 10%)

## ğŸ“ Linuså¼å¼€å‘å“²å­¦

> **"Talk is cheap. Show me the code."**

æˆ‘ä»¬çš„åŸåˆ™:

1. âœ… **ä¿®å¤åŸºç¡€é—®é¢˜ä¼˜å…ˆ** - LR/warmup/scheduler
2. âœ… **ç®€å•ç›´æ¥çš„æ–¹æ¡ˆ** - No fancy tricks
3. âœ… **å¯è§†åŒ–éªŒè¯** - ä¸€å›¾èƒœåƒè¨€
4. âŒ **é¿å…è¿‡æ—©ä¼˜åŒ–** - å…ˆè®©åŸºç¡€work

### æˆ‘ä»¬åšçš„

- æ­£ç¡®çš„learning rate
- Proper warmup schedule
- å®æ—¶å¯è§†åŒ–ç›‘æ§

### æˆ‘ä»¬æ²¡åš (å¥½å“å‘³)

- ~~å¤æ‚çš„optimizer~~
- ~~èŠ±å“¨çš„augmentation~~
- ~~æ¶æ„æœç´¢~~
- ~~Ensemble~~

**åŸå› **: åŸºç¡€è®­ç»ƒéƒ½æ²¡æå¯¹ï¼Œä¼˜åŒ–è¿™äº›æ²¡æ„ä¹‰ã€‚

## ğŸ“ æ›´æ–°æ—¥å¿—

### 2024-11-15 - è®­ç»ƒä¼˜åŒ–

- ğŸ”´ **Critical Fix**: Learning rate 1e-4 â†’ 5e-4
- ğŸ”´ **Critical Fix**: æ·»åŠ 5 epoch warmup
- ğŸ”´ **Critical Fix**: ä¿®å¤scheduleræ—¶æœº
- âœ¨ **Feature**: å®æ—¶è®­ç»ƒå¯è§†åŒ–
- âœ¨ **Feature**: History tracking in checkpoints
- ğŸ“Š **Improvement**: é¢„æœŸå‡†ç¡®ç‡ä»27.6%æå‡åˆ°70-85%

### 2024-11-14 - é¡¹ç›®åˆå§‹åŒ–

- æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
- åŸºçº¿æ¨¡å‹å®ç°
- è®­ç»ƒæµç¨‹æ­å»º

## ğŸ¤ è´¡çŒ®æŒ‡å—

éµå¾ªLinusçš„åŸåˆ™:

1. **ä»£ç è´¨é‡** > åŠŸèƒ½æ•°é‡
2. **ç®€å•æ–¹æ¡ˆ** > å¤æ‚æ–¹æ¡ˆ
3. **å®é™…æµ‹è¯•** > ç†è®ºåˆ†æ
4. **é›¶åºŸè¯** > é•¿ç¯‡å¤§è®º

## ğŸ“„ License

MIT License

## ğŸ™ è‡´è°¢

- Linus Torvalds - ä¸ºä¼˜ç§€ä»£ç å“å‘³æ ‘ç«‹æ ‡å‡†
- PyTorch Team - ä¼˜ç§€çš„æ·±åº¦å­¦ä¹ æ¡†æ¶
- timm - é¢„è®­ç»ƒæ¨¡å‹åº“

---

**é¡¹ç›®çŠ¶æ€**: âœ… å¯ç”¨  
**æœ€ä½³å‡†ç¡®ç‡**: å¾…è®­ç»ƒ (é¢„æœŸ70-85%)  
**æœ€åæ›´æ–°**: 2024-11-15

**å¼€å§‹è®­ç»ƒ**: `bash train_improved.sh` ğŸš€